# EPL-Betting-Model

This repository contains two R markdown files, the first trains and validates a machine learning model which generates three probabilities; the home team winning, visiting team winning, and a draw. The second file deploys the model against the day’s games and calculates the “edge” of each pick as defined by the implied probability of the given odds to win minus the probability of winning provided by the model.  

The XGBoost model is trained on English Premiere League (EPL) over 1500 games (70%) between 2017-2021 using data provided by www.fbref.com via the WorldfootballR package. The model was validated on 641 (30%) games played in 2021-22 and 2022-23. After ingestion, the data required cleaning to create consistent team names, drop non-EPL games, and create a dependent factorial variable called “Result”. The next step was feature engineering to assign unique game IDs to each team. Next, I chose which of the 218 variables to include in the model. For each selected variable, I calculated season-to-date and recent (defined as last 4) for both home and away teams.  In summing each statistic, I subtracted the statistics from that day’s game to avoid data leakage. This feature is important when choosing the number of games to include in recent performance. Because the roll away function will sum that day’s games, the value of k should be one higher than the number of games you want to evaluate (e.g. if you want to look at the last 7 games, the value of k should be 8). I also added the betting odds for each match as well as Pythagorean points metric, suggesting how many points a team “should have” based on their goal differential.  

The tooling used to collect the data returns game results for each team, resulting in two observations for each game; one from the perspective of the home team and the same data from that of the away team. The data needed to be transformed to combine the statistics from the home and away team into a single observation representing a single game. To do this, we create a unique ID for each game assigned to each team playing in the game, and split the data into home and away, and perform a left join on the game ID present in both data sets. 

After cleaning and feature engineering, I perform cross validation to determine the optimal number of trees to train. After fitting the model, it is validated on 2021-22 games.  The overall accuracy is 56%. With 95% confidence, we can expect the overall accuracy to fall between 52 and 60 percent. I’ve also included an importance matrix to which variables are most influential in predicting winners.

The deployment file first ingests the most recent data and cleans it followed by performing the necessary feature engineering to ensure the data’s format exactly matches what the model was trained on.  To identify where any potential value lies, the user will need to manually input the home and away teams as well as the odds for each team to win or draw. Comments are in the code to indicate where this needs to occur. 

The output will be a csv file with each game and, the model’s probability of each team winning, the implied probability from the odds, as well as the expected value of each pick. 
